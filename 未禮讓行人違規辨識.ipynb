{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenchun0731/city-hunter/blob/main/%E6%9C%AA%E7%A6%AE%E8%AE%93%E8%A1%8C%E4%BA%BA%E9%81%95%E8%A6%8F%E8%BE%A8%E8%AD%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNzLMwH0w8y2",
        "outputId": "446a4369-ff14-4355-ca36-ad988130e5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#掛載雲端硬碟\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content')"
      ],
      "metadata": {
        "id": "tPHrmvaSqxOj"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install numpy\n",
        "!pip install pytesseract\n",
        "!pip install ultralytics\n",
        "!pip install deep-sort-realtime\n",
        "!pip install import-ipynb\n",
        "!apt install tesseract-ocr\n",
        "!apt install libtesseract-dev\n",
        "!pip install pytesseract\n",
        "!pip install pillow\n",
        "!pip install opencv-python\n",
        "!pip install opencv-python-headless\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2WfFxL5qfep",
        "outputId": "9649388f-1683-462b-9423-5874312e3a48"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime) (4.10.0.84)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.10/dist-packages (0.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (7.34.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from import-ipynb) (5.10.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->import-ipynb) (4.9.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->import-ipynb) (5.7.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.13)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plates_identify\n",
        "import crosswalkconnect"
      ],
      "metadata": {
        "id": "GVKZLoqUqzt1"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 連接資料庫"
      ],
      "metadata": {
        "id": "bgze3p12d3iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mysql-connector-python  # MySQL 範例"
      ],
      "metadata": {
        "id": "Gm4wX-jwL7kM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc766733-f5f5-423a-a040-2c23020fac43"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mysql-connector-python in /usr/local/lib/python3.10/dist-packages (9.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import相關套件\n",
        "import mysql.connector\n",
        "import pandas.io.sql as sql\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "PjFPOpF6j-Wb"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mysql.connector\n",
        "\n",
        "\n",
        "#連結到資料庫\n",
        "config = {\n",
        "    'user':'113403',\n",
        "    'password':'@All3403@',\n",
        "    'host':'140.131.114.242',\n",
        "    'database':'113-law'\n",
        "}\n",
        "cnx=mysql.connector.connect(**config)\n",
        "cursor = cnx.cursor()\n",
        "#使用SQL語法讀取資料表\n",
        "df=sql.read_sql('select * from testapp_car;',cnx)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6GDPw0pVeGAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e39f48bb-93ba-41db-9de5-b3286be759ed"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-1047c5645cdd>:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df=sql.read_sql('select * from testapp_car;',cnx)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolov8"
      ],
      "metadata": {
        "id": "pbUbyhuXty6y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv6NmQRulRti",
        "outputId": "cb97138d-585c-4e22-b6b1-30ed0d44961e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.49)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "#下載ultralytics開源庫\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpsQ-_ZQkLGA",
        "outputId": "3d458c2a-e5d7-456c-f0bb-79a14ce571fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 900, in entrypoint\n",
            "    check_dict_alignment(full_args_dict, {a: \"\"})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 485, in check_dict_alignment\n",
            "    raise SyntaxError(string + CLI_HELP_MSG) from e\n",
            "SyntaxError: '\u001b[31m\u001b[1mYOLO\u001b[0m' is not a valid YOLO argument. \n",
            "\n",
            "    Arguments received: ['yolo', 'model=checks#检查', 'YOLO', '模型的状态或配置信息。']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'segment', 'pose', 'obb', 'detect', 'classify'}\n",
            "                MODE (required) is one of {'export', 'benchmark', 'track', 'val', 'predict', 'train'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Streamlit real-time webcam inference GUI\n",
            "        yolo streamlit-predict\n",
            "\n",
            "    6. Ultralytics solutions usage\n",
            "        yolo solutions count or in ['heatmap', 'queue', 'speed', 'workout', 'analytics', 'trackzone'] source=\"path/to/video/file.mp4\"\n",
            "\n",
            "    7. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "        yolo solutions help\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Solutions: https://docs.ultralytics.com/solutions/\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "#下載YOLOv8並檢查模型配置\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "from IPython.display import display,Image\n",
        "from IPython import display\n",
        "display.clear_output()#清除当前输出单元格的所有输出内容\n",
        "!yolo model=checks#检查 YOLO 模型的状态或配置信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 主程式"
      ],
      "metadata": {
        "id": "CNbdiZ5hwUdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF93zuCo23Te",
        "outputId": "622a36ee-728e-426e-a42a-f24ca8d0a9b6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "egyWxqJf20EF"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deep sort\n",
        "#DeepSort(使用自己的訓練檔)\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import copy\n",
        "import os\n",
        "import import_ipynb\n",
        "import sys\n",
        "\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "\n",
        "#輸入\n",
        "model = YOLO('/content/drive/MyDrive/Finetune/Licence_Finetune/train/train/weights/best.pt')\n",
        "cap = cv2.VideoCapture(\"/content/drive/MyDrive/usefile/755441932.458752.mp4\")#輸入影片\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "fNUMS = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "videoWriter = cv2.VideoWriter(\"/content/drive/MyDrive/Finetune/Licence_Finetune/detect/predict005.mp4\", fourcc, fps, size)#輸出位置\n",
        "\n",
        "\n",
        "#nms_max_overlap非極大值抑制（NMS）過程中允許的最大重疊比例\n",
        "#nn_budget控制最近鄰搜尋中使用的樣本數量的上限\n",
        "#min_hits: 設定物體被確認為有效跟蹤需要的最小幀數。增大 min_hits 可以避免追蹤器誤認為是有效的目標，從而減少漂移。\n",
        "tracker = DeepSort(\n",
        "    max_age=30,  # 增加此值以保持更長時間的追蹤\n",
        "    max_cosine_distance=0.8, # 減少此值以提高特徵匹配的精確度一般設置為0到1之間\n",
        "    nn_budget=100  # 調整最近鄰搜尋的樣本數量\n",
        ")\n",
        "\n",
        "# 定義顏色字典\n",
        "colors = {\n",
        "    'ambulance':(0,255,0),   # 綠色\n",
        "    'bus': (0,130,255),     # 青色\n",
        "    'car': (0,255,0),      # 藍色\n",
        "    'fire truck': (255,0,0),  # 紅色\n",
        "    'licence': (60,0,128),   # 紫色\n",
        "    'person': (255,255,0),   # 黃色\n",
        "    'police': (0,0,0),     # 黑色\n",
        "    'traffic light': (255,0,255) # 粉紅色\n",
        "}\n",
        "rule_id=[]\n",
        "violation_frame_count=[]\n",
        "rule_plates=[]\n",
        "class TrafficViolationDetector:\n",
        "    def __init__(self, image_data, up_information, low_information, frame_count, frame, image_data_copy, point_all):\n",
        "        self.image_data = image_data\n",
        "        self.image_data_copy=image_data_copy\n",
        "        self.frame = frame\n",
        "        self.up_information = up_information\n",
        "        self.low_information = low_information\n",
        "        self.frame_count=frame_count\n",
        "        self.point_all=point_all\n",
        "\n",
        "    def detect_violations(self):\n",
        "        return self.data_sort()\n",
        "\n",
        "\n",
        "    def data_sort(self):\n",
        "      if 'person' in self.image_data and 'car' in self.image_data:\n",
        "          for tag, data in self.image_data.items():\n",
        "              if tag=='car' or tag=='person':\n",
        "\n",
        "                for data_k, data_v in data.items():\n",
        "                    # 確保 data_v 是列表而不是字符串\n",
        "                    if isinstance(data_v, list):\n",
        "                        for id, coordinate in enumerate(data_v):\n",
        "                            # 檢查是否為有效的坐標\n",
        "                            if len(coordinate) >= 2 and self.on_crosswalk(coordinate[0], coordinate[1]):\n",
        "                                data_v[id] = coordinate\n",
        "                            else:\n",
        "                                data_v[id] = []\n",
        "                        # 過濾空陣列\n",
        "                        self.image_data[tag][data_k] = [item for item in data_v if item]\n",
        "          return self.rule_judge()\n",
        "\n",
        "\n",
        "\n",
        "    def on_crosswalk(self,x,y):\n",
        "        # 分別提取 x 和 y 值\n",
        "        x_values = [point[0] for point in self.point_all]\n",
        "        y_values = [point[1] for point in self.point_all]\n",
        "\n",
        "        # 計算最小值與最大值\n",
        "        x_min = min(x_values)\n",
        "        x_max = max(x_values)\n",
        "        y_min = min(y_values)\n",
        "        y_max = max(y_values)\n",
        "        if x_min <= x <= x_max and y_min <= y <= y_max:\n",
        "          up_slope=self.up_information[0]\n",
        "          up_intercept=self.up_information[1]\n",
        "          low_slope=self.low_information[0]\n",
        "          low_intercept=self.low_information[1]\n",
        "\n",
        "          low_y = low_slope * x + low_intercept\n",
        "          up_y = up_slope * x + up_intercept\n",
        "          return up_y > y > low_y\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "    def rule_judge(self):\n",
        "        people_data = self.image_data['person']\n",
        "        car_data = self.image_data['car']\n",
        "\n",
        "        for c_k, c_v in car_data.items():\n",
        "\n",
        "            is_violation = False\n",
        "            for p_v in people_data.values():\n",
        "\n",
        "                if is_violation:\n",
        "                    break\n",
        "                for c_data, p_data in [[c, p] for c in c_v for p in p_v]:\n",
        "\n",
        "                    if self.distance_cal(c_data, p_data):\n",
        "                        is_violation = True\n",
        "                        violate_information=self.you_violation(c_k)\n",
        "                        return violate_information\n",
        "\n",
        "\n",
        "    def distance_cal(self, car, person):\n",
        "        point_all_copy=copy.deepcopy(self.point_all)\n",
        "        point_all_copy.append(car)\n",
        "        point_all_copy.append(person)\n",
        "\n",
        "        sorted_point_all = sorted(point_all_copy, key=lambda x: x[0])\n",
        "        car_index=sorted_point_all.index(car)\n",
        "        person_index=sorted_point_all.index(person)\n",
        "\n",
        "        return abs(car_index-person_index) <= 3\n",
        "\n",
        "    def you_violation(self, id):\n",
        "        if id not in rule_id:\n",
        "\n",
        "            violation_frame_count.append(self.frame_count)\n",
        "            #找到違規車輛的車牌是多少的函示\n",
        "            plates_id=self.find_plates(id)\n",
        "            if plates_id == None:\n",
        "              rule_id.append(id)\n",
        "              return None\n",
        "            else:\n",
        "              rule_id.append(id)\n",
        "              # rule_plates.append(plates_id)\n",
        "              car_img_croppped,plates_img_cropped=self.load_on_database(id,plates_id)\n",
        "              return [self.frame_count,car_img_croppped,plates_img_cropped]\n",
        "            # print(f'在第{self.frame_count}偵的時候，車輛{id}違規,他的車牌id是{plates_id}')\n",
        "            # self.clear_list(self.image_data)\n",
        "\n",
        "    # # 定義清空列表的函式\n",
        "    # def clear_list(self,lst):\n",
        "    #     lst.clear()  # 使用 clear() 方法清空列表\n",
        "\n",
        "    def coor_min_max(self,what_coor):\n",
        "        min_value = min(min(sublist) for sublist in what_coor)\n",
        "        max_value = max(max(sublist) for sublist in what_coor)\n",
        "        return min_value,max_value\n",
        "    def find_plates(self,id):\n",
        "        #從image_data['car'][id]找到車輛座標\n",
        "        rule_car_coordinate=self.image_data['car'][id]\n",
        "        if 'licence' in self.image_data:\n",
        "          rule_plates_coordinate=self.image_data['licence']\n",
        "\n",
        "\n",
        "\n",
        "          all_distance=[]\n",
        "          car_min,car_max=self.coor_min_max(rule_car_coordinate)\n",
        "          for plates_id,plates_coordinates in rule_plates_coordinate.items():\n",
        "            plates_min,plates_max=self.coor_min_max(plates_coordinates)\n",
        "            x_minus = abs(plates_min - car_min)\n",
        "            y_minus = abs(plates_max - car_max)\n",
        "            if y_minus == 0:\n",
        "                distance = x_minus\n",
        "\n",
        "            elif x_minus == 0:\n",
        "                distance = y_minus\n",
        "            else:\n",
        "                distance = math.hypot(x_minus, y_minus)\n",
        "            all_distance.append([plates_id,distance])\n",
        "          cars_plates_id = min(all_distance, key=lambda x: x[1])\n",
        "          return cars_plates_id[0]\n",
        "        else:\n",
        "\n",
        "          return None\n",
        "\n",
        "    def load_on_database(self,id,plates_id):\n",
        "        car_cropped_img=self.img_cropped('car',id)\n",
        "        plate_cropped_img=self.img_cropped('licence',plates_id)\n",
        "\n",
        "        # _, car_img_encoded = cv2.imencode('.jpg', car_cropped_img)\n",
        "        # _, plate_img_encoded = cv2.imencode('.jpg', plate_cropped_img)\n",
        "\n",
        "        # return car_img_encoded.tobytes(), plate_img_encoded.tobytes()\n",
        "        return car_cropped_img, plate_cropped_img\n",
        "\n",
        "    def img_cropped(self,object,coorid):\n",
        "        object_coordinate=self.image_data_copy[object][coorid]\n",
        "\n",
        "        # 找到 x 和 y 的最小最大值\n",
        "        x_min = min(point[0] for point in object_coordinate)  # 找到最小的 x 值\n",
        "        x_max = max(point[0] for point in object_coordinate)  # 找到最大的 x 值\n",
        "        y_min = min(point[1] for point in object_coordinate)  # 找到最小的 y 值\n",
        "        y_max = max(point[1] for point in object_coordinate)  # 找到最大的 y 值\n",
        "        # print(object_coordinate)\n",
        "        # 直接裁剪图像（矩形）\n",
        "        cropped_img = self.frame[y_min:y_max, x_min:x_max]\n",
        "        return cropped_img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#＃＃ 計數器\n",
        "frame_count = 0\n",
        "\n",
        "# 儲存追蹤框位置的字典\n",
        "image_data = {}\n",
        "\n",
        "def box_label(image, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n",
        "    #int(box[0]): 左邊界的 x 坐標，即框的左側位置（水平坐標）。\n",
        "    #int(box[1]): 上邊界的 y 坐標，即框的上側位置（垂直坐標）。\n",
        "    #int(box[2]): 右邊界的 x 坐標，即框的右側位置（水平坐標）。\n",
        "    #int(box[3]): 下邊界的 y 坐標，即框的下側位置（垂直坐標）。\n",
        "    p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n",
        "\n",
        "    # 畫出矩形框\n",
        "    cv2.rectangle(image, p1, p2, color, thickness=3, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        w, h = cv2.getTextSize(label, 0, fontScale=2 / 3, thickness=3)[0]\n",
        "        outside = p1[1] - h >= 3\n",
        "        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n",
        "        cv2.rectangle(image, p1, p2, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(image,\n",
        "                    label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n",
        "                    0, 2/3, txt_color, thickness=3, lineType=cv2.LINE_AA)\n",
        "\n",
        "\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "    draw_frame=frame.copy()\n",
        "\n",
        "    if success:\n",
        "\n",
        "        results = model(frame, conf=0.2, iou=0.3)#置信值\n",
        "        outputs = results[0].boxes.data.cpu().numpy()\n",
        "\n",
        "        detections = []\n",
        "\n",
        "        if outputs is not None:\n",
        "            for output in outputs:\n",
        "                x1, y1, x2, y2 = list(map(int, output[:4]))\n",
        "                class_id = int(output[5])\n",
        "\n",
        "                # 根據模型的類別對應，將class_id對應到具體的類別名稱\n",
        "                if class_id == 0:\n",
        "                    label = 'ambulance'\n",
        "                elif class_id == 1:\n",
        "                    label = 'bus'\n",
        "                elif class_id == 2:\n",
        "                    label = 'car'\n",
        "                elif class_id == 3:\n",
        "                    label = 'fire truck'\n",
        "                elif class_id == 4:\n",
        "                    label = 'licence'\n",
        "                elif class_id == 5:\n",
        "                    label = 'person'\n",
        "                elif class_id == 6:\n",
        "                    label = 'police'\n",
        "                elif class_id == 7:\n",
        "                    label = 'traffic light'\n",
        "\n",
        "                color = colors.get(label, (128, 128, 128))  # 默認顏色\n",
        "\n",
        "                detections.append(([x1, y1, int(x2-x1), int(y2-y1)], output[4], label))\n",
        "\n",
        "            tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "            for track in tracks:\n",
        "                if not track.is_confirmed():\n",
        "                    continue\n",
        "\n",
        "                track_id = track.track_id #追蹤框id\n",
        "                bbox = track.to_ltrb()\n",
        "\n",
        "                # 獲取對應的顏色\n",
        "                label = track.det_class\n",
        "                if track_id in rule_id:\n",
        "                  color = (0,0,255)\n",
        "                  tickness=5\n",
        "\n",
        "                else:\n",
        "                  color = colors.get(label, (128, 128, 128))  # 默認顏色\n",
        "                  tickness=2\n",
        "\n",
        "                box_label(draw_frame, bbox, '#' + str(int(track_id)) + label, color)\n",
        "\n",
        "                track_id_n=1000\n",
        "                bbox_n=[550,250,650,450]\n",
        "                color_n=(255,255,0)\n",
        "                tickness_n=2\n",
        "                label_n='person'\n",
        "\n",
        "                box_label(draw_frame, bbox_n, '#' + str(int(track_id_n)) + label_n, color_n)\n",
        "                # 儲存追蹤框位置\n",
        "                if frame_count % 10 == 0:\n",
        "\n",
        "                  # 將角點格式化為所需的字串格式\n",
        "                  p1 = [int(bbox[0]), int(bbox[1])]  # 左上角\n",
        "                  p2 = [int(bbox[2]), int(bbox[3])]  # 右下角\n",
        "                  image_position =  [\n",
        "                        [p1[0], p1[1]],  # 左上角\n",
        "                        [p1[0], p2[1]],  # 左下角\n",
        "                        [p2[0], p2[1]],  # 右下角\n",
        "                        [p2[0], p1[1]]   # 右上角\n",
        "                    ]\n",
        "\n",
        "\n",
        "                  # 檢查是否存在此label\n",
        "                  if label not in image_data:\n",
        "                    image_data[label] = {}  # 如果沒有此label，則新增一個字典\n",
        "\n",
        "                  # 檢查此label下是否存在此track_id\n",
        "                  if track_id not in image_data[label]:\n",
        "                    image_data[label][track_id] = image_position\n",
        "\n",
        "\n",
        "                  label='person'\n",
        "\n",
        "\n",
        "                  # 檢查是否存在此label\n",
        "                  if label not in image_data:\n",
        "                    image_data[label] = {}  # 如果沒有此label，則新增一個字典\n",
        "\n",
        "                  new_people=[[550,250], [550, 450], [650,450], [650, 250]]\n",
        "                  image_data[label]['1000'] = new_people\n",
        "\n",
        "\n",
        "            image_data_copy = copy.deepcopy(image_data)\n",
        "            print(image_data)\n",
        "                  # rule_id = []\n",
        "            if frame_count == 0:\n",
        "                  crossWalkIdentify=crosswalkconnect.identify_crosswalk(frame)\n",
        "                  point_all,up_information,low_information=crossWalkIdentify.main_crosswalk()\n",
        "                  print(point_all,up_information,low_information)\n",
        "\n",
        "\n",
        "            if frame_count % 1 == 0:\n",
        "\n",
        "\n",
        "                  detector = TrafficViolationDetector(image_data, up_information, low_information, frame_count, frame, image_data_copy, point_all)\n",
        "                  violate_result=detector.detect_violations()\n",
        "                  if violate_result is not None:\n",
        "                    # 上傳照片到 Colab\n",
        "                    # 獲取當前時間並格式化\n",
        "                    print('違規')\n",
        "                    cv2_imshow(violate_result[1])\n",
        "                    seconds = round(violate_result[0] / 60 , 2)\n",
        "                    _, car_img_encoded = cv2.imencode('.jpg', violate_result[1])\n",
        "                    _, plate_img_encoded = cv2.imencode('.jpg', violate_result[2])\n",
        "                    car_image_data = car_img_encoded.tobytes()\n",
        "                    plate_image_data = plate_img_encoded.tobytes()\n",
        "\n",
        "\n",
        "\n",
        "                    image=violate_result[2]\n",
        "                    resule=plates_identify.plates_OCR(image)\n",
        "\n",
        "                    text=resule.main()\n",
        "                    if text==None:\n",
        "                      text=0\n",
        "\n",
        "                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "                    data = {\n",
        "                        'license_plate': [text],\n",
        "                        'date_time': [current_time],  # 使用當下時間\n",
        "                        'location': ['TAIPEI'],\n",
        "                        'violation': ['未禮讓行人'],  # 填闖紅燈或未禮讓行人\n",
        "                        'seconds': [seconds],  # 違規當下的秒數\n",
        "                        'car_image': [car_image_data],\n",
        "                        'plate_image': [plate_image_data]\n",
        "                    }\n",
        "\n",
        "                    # 建立 DataFrame\n",
        "                    df = pd.DataFrame(data)\n",
        "                    # SQL插入语句\n",
        "                    add_violation = (\"INSERT INTO testapp_car \"\n",
        "                                    \"(license_plate, date_time, location, violation, seconds, car_image, plate_image) \"\n",
        "                                    \"VALUES (%s, %s, %s, %s, %s, %s, %s)\")\n",
        "\n",
        "                    # 将DataFrame中的每一行数据插入到数据库中\n",
        "                    for index, row in df.iterrows():\n",
        "                        data_violation = (row['license_plate'], row['date_time'], row['location'], row['violation'], row['seconds'], row['car_image'], row['plate_image'])\n",
        "                        cursor.execute(add_violation, data_violation)\n",
        "\n",
        "                    # 提交事务\n",
        "                    cnx.commit()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #  清空字典\n",
        "            image_data.clear()\n",
        "            image_data_copy.clear()\n",
        "\n",
        "\n",
        "        cv2.putText(draw_frame, \"https://blog.csdn.net/zhaocj\", (25, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "        videoWriter.write(draw_frame)\n",
        "        frame_count += 1  # 每幀加1\n",
        "\n",
        "    else:\n",
        "        break\n",
        "cursor.close()\n",
        "cnx.close()\n",
        "cap.release()\n",
        "videoWriter.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "s5g6pnmeEfuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db58bc0f-7fd1-478c-edf0-41741e27ba62"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 car, 42.3ms\n",
            "Speed: 2.1ms preprocess, 42.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "[[1190, 597], [231, 625], [371, 531], [475, 462], [561, 408], [629, 367], [685, 333], [732, 305], [773, 281], [1193, 310]] (-0.7, 883.664) (-0.355, 562.172)\n",
            "\n",
            "0: 384x640 (no detections), 32.8ms\n",
            "Speed: 4.6ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 29.1ms\n",
            "Speed: 1.8ms preprocess, 29.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 29.1ms\n",
            "Speed: 1.8ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 29.1ms\n",
            "Speed: 2.7ms preprocess, 29.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.3ms\n",
            "Speed: 2.0ms preprocess, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 23.2ms\n",
            "Speed: 2.0ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 23.2ms\n",
            "Speed: 3.0ms preprocess, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.8ms\n",
            "Speed: 2.2ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.0ms\n",
            "Speed: 2.9ms preprocess, 22.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.1ms\n",
            "Speed: 3.3ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[574, 122], [574, 242], [719, 242], [719, 122]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 22.1ms\n",
            "Speed: 1.9ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.4ms\n",
            "Speed: 2.5ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 21.9ms\n",
            "Speed: 2.8ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.5ms\n",
            "Speed: 2.5ms preprocess, 22.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.2ms\n",
            "Speed: 2.5ms preprocess, 22.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.1ms\n",
            "Speed: 2.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.7ms\n",
            "Speed: 2.7ms preprocess, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.0ms\n",
            "Speed: 2.6ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 21.9ms\n",
            "Speed: 4.5ms preprocess, 21.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 27.9ms\n",
            "Speed: 5.9ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[560, 133], [560, 262], [710, 262], [710, 133]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 23.3ms\n",
            "Speed: 3.8ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.1ms\n",
            "Speed: 6.8ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 21.9ms\n",
            "Speed: 2.5ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 21.9ms\n",
            "Speed: 1.9ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.4ms\n",
            "Speed: 5.0ms preprocess, 22.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.5ms\n",
            "Speed: 3.4ms preprocess, 22.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.2ms\n",
            "Speed: 2.6ms preprocess, 22.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.4ms\n",
            "Speed: 2.6ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.0ms\n",
            "Speed: 3.0ms preprocess, 22.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[551, 135], [551, 284], [712, 284], [712, 135]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 22.6ms\n",
            "Speed: 4.2ms preprocess, 22.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.9ms\n",
            "Speed: 4.4ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 21.9ms\n",
            "Speed: 5.3ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 22.8ms\n",
            "Speed: 3.9ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.9ms\n",
            "Speed: 3.1ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.8ms\n",
            "Speed: 2.0ms preprocess, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.7ms\n",
            "Speed: 2.2ms preprocess, 25.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.0ms\n",
            "Speed: 3.1ms preprocess, 25.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.9ms\n",
            "Speed: 2.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[570, 145], [570, 308], [743, 308], [743, 145]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 26.1ms\n",
            "Speed: 2.7ms preprocess, 26.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.5ms\n",
            "Speed: 3.5ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.0ms\n",
            "Speed: 2.9ms preprocess, 26.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 25.6ms\n",
            "Speed: 4.3ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 27.9ms\n",
            "Speed: 2.8ms preprocess, 27.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.3ms\n",
            "Speed: 2.8ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.4ms\n",
            "Speed: 2.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.6ms\n",
            "Speed: 2.0ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.5ms\n",
            "Speed: 2.4ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[591, 151], [591, 335], [797, 335], [797, 151]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 27.1ms\n",
            "Speed: 1.9ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 27.1ms\n",
            "Speed: 2.0ms preprocess, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 27.2ms\n",
            "Speed: 2.2ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 27.1ms\n",
            "Speed: 2.2ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 3 cars, 27.1ms\n",
            "Speed: 1.9ms preprocess, 27.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 3 cars, 31.6ms\n",
            "Speed: 9.3ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 3 cars, 32.7ms\n",
            "Speed: 2.1ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 33.7ms\n",
            "Speed: 2.2ms preprocess, 33.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 1.9ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 2.0ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[625, 165], [625, 374], [894, 374], [894, 165]], '5': [[520, 92], [520, 164], [640, 164], [640, 92]], '6': [[88, 160], [88, 326], [382, 326], [382, 160]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 29.5ms\n",
            "Speed: 2.1ms preprocess, 29.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 29.5ms\n",
            "Speed: 2.1ms preprocess, 29.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 30.2ms\n",
            "Speed: 2.1ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 2.0ms preprocess, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.7ms\n",
            "Speed: 2.2ms preprocess, 29.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.7ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 31.6ms\n",
            "Speed: 1.8ms preprocess, 31.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 1.9ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 2.0ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 4.4ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[677, 162], [677, 416], [1045, 416], [1045, 162]], '5': [[453, 112], [453, 179], [573, 179], [573, 112]], '6': [[-30, 169], [-30, 354], [297, 354], [297, 169]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.2ms preprocess, 29.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 1.9ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 1.9ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 29.0ms\n",
            "Speed: 2.2ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.2ms preprocess, 29.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 34.2ms\n",
            "Speed: 5.1ms preprocess, 34.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 2.1ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.1ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.0ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.1ms preprocess, 29.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[774, 172], [774, 462], [1247, 462], [1247, 172]], '5': [[363, 125], [363, 203], [510, 203], [510, 125]], '6': [[-149, 179], [-149, 382], [212, 382], [212, 179]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 2 cars, 29.3ms\n",
            "Speed: 4.1ms preprocess, 29.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 5.0ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.0ms\n",
            "Speed: 2.0ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.7ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.1ms\n",
            "Speed: 2.2ms preprocess, 29.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 32.1ms\n",
            "Speed: 3.4ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 29.9ms\n",
            "Speed: 3.6ms preprocess, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 30.1ms\n",
            "Speed: 3.0ms preprocess, 30.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 30.0ms\n",
            "Speed: 2.2ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 29.9ms\n",
            "Speed: 2.0ms preprocess, 29.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[845, 191], [845, 500], [1350, 500], [1350, 191]], '5': [[262, 141], [262, 229], [431, 229], [431, 141]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 29.9ms\n",
            "Speed: 2.0ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 28.8ms\n",
            "Speed: 2.0ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.2ms\n",
            "Speed: 2.1ms preprocess, 26.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.0ms\n",
            "Speed: 2.6ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.9ms\n",
            "Speed: 2.1ms preprocess, 25.9ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.9ms\n",
            "Speed: 2.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.8ms\n",
            "Speed: 2.1ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 25.2ms\n",
            "Speed: 3.4ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 2 cars, 29.7ms\n",
            "Speed: 5.3ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 30.1ms\n",
            "Speed: 2.1ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[927, 204], [927, 541], [1477, 541], [1477, 204]], '5': [[129, 157], [129, 268], [340, 268], [340, 157]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 25.2ms\n",
            "Speed: 1.9ms preprocess, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.2ms\n",
            "Speed: 2.0ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 2.2ms preprocess, 25.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 25.3ms\n",
            "Speed: 4.8ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 (no detections), 25.2ms\n",
            "Speed: 1.7ms preprocess, 25.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.2ms\n",
            "Speed: 2.4ms preprocess, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.3ms\n",
            "Speed: 2.6ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.1ms\n",
            "Speed: 2.6ms preprocess, 25.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.1ms\n",
            "Speed: 2.8ms preprocess, 25.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.6ms\n",
            "Speed: 3.5ms preprocess, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'2': [[1009, 218], [1009, 582], [1603, 582], [1603, 218]], '5': [[16, 175], [16, 303], [255, 303], [255, 175]], '8': [[537, 89], [537, 158], [657, 158], [657, 89]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 4.0ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 3.6ms preprocess, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.5ms\n",
            "Speed: 1.9ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 2.7ms preprocess, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 28.6ms\n",
            "Speed: 2.2ms preprocess, 28.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 6.2ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 27.4ms\n",
            "Speed: 2.1ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 32.5ms\n",
            "Speed: 2.3ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 5.3ms preprocess, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 5.2ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{'car': {'5': [[-98, 193], [-98, 337], [170, 337], [170, 193]], '8': [[476, 96], [476, 172], [609, 172], [609, 96]]}, 'person': {'1000': [[550, 250], [550, 450], [650, 450], [650, 250]]}}\n",
            "\n",
            "0: 384x640 1 car, 32.3ms\n",
            "Speed: 3.1ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 40.0ms\n",
            "Speed: 2.3ms preprocess, 40.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 24.4ms\n",
            "Speed: 2.1ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 34.6ms\n",
            "Speed: 2.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.3ms\n",
            "Speed: 2.1ms preprocess, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 25.0ms\n",
            "Speed: 2.6ms preprocess, 25.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n",
            "\n",
            "0: 384x640 1 car, 26.9ms\n",
            "Speed: 2.1ms preprocess, 26.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SuexAHUAu8z6"
      },
      "execution_count": 101,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "bgze3p12d3iw",
        "pbUbyhuXty6y"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}